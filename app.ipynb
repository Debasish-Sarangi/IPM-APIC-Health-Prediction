{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e18b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8080/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import joblib\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "from datetime import datetime, date, time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os, types\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "clf = joblib.load('APIPredict.pkl')\n",
    "\n",
    "from train import MultiColumnLabelEncoder\n",
    "\n",
    "\n",
    "preprocessing_1 = joblib.load('Preprocessing_1.pkl')\n",
    "preprocessing_2 = joblib.load('Preprocessing_2.pkl')\n",
    "\n",
    "\n",
    "###################################################\n",
    "def pre_processing(df_data_1_replace):\n",
    "    df_data_1_replace['ScheduledDay_year'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.year\n",
    "    df_data_1_replace['ScheduledDay_month'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.month\n",
    "    df_data_1_replace['ScheduledDay_week'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.week\n",
    "    df_data_1_replace['ScheduledDay_day'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.day\n",
    "    df_data_1_replace['ScheduledDay_hour'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.hour\n",
    "    df_data_1_replace['ScheduledDay_minute'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.minute\n",
    "    df_data_1_replace['ScheduledDay_dayofweek'] = pd.to_datetime(df_data_1_replace['datetimestamp']).dt.dayofweek\n",
    "\n",
    "    df_data_1_replace.drop(['datetimestamp'], axis='columns', inplace=True)\n",
    "\n",
    "    # column_to_move = df_data_1_replace.pop(\"status_code\")\n",
    "    # df_data_1_replace.insert(len(df_data_1_replace.columns), \"status_code\", column_to_move)\n",
    "    # df_data_1_replace.head(5)\n",
    "\n",
    "    no_columns = len(df_data_1_replace.columns)\n",
    "    train_columns = no_columns\n",
    "    # OriginalX = df_data_1_replace.apply(LE)\n",
    "    try:\n",
    "        OriginalX = preprocessing_1.transform(df_data_1_replace)\n",
    "        X = preprocessing_2.transform(OriginalX.iloc[:, 0:train_columns])\n",
    "\n",
    "    except:\n",
    "        X='Exception'\n",
    "\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "###################################################\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return flask.render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "\n",
    "def predict():\n",
    "    to_predict_list = request.form.to_dict()\n",
    "\n",
    "    data = [to_predict_list]\n",
    "    df = pd.DataFrame(data, columns=['datetimestamp', 'client_ip', 'gateway_ip'])\n",
    "    #df['status_code'] = '0'\n",
    "    transformed_data = pre_processing(df)\n",
    "    if(transformed_data!='Exception'):\n",
    "        pred = clf.predict(transformed_data)\n",
    "    else:\n",
    "        pred=\"-1\"\n",
    "    # prob = clf.predict_proba(count_vect.transform([review_text]))\n",
    "    # pr =  1\n",
    "\n",
    "    if pred[0] == 1:\n",
    "        prediction = \"200\"\n",
    "        # pr = prob[0][0]\n",
    "    elif pred[0] == 2:\n",
    "        prediction = \"401\"\n",
    "    elif pred[0] == 3:\n",
    "        prediction = \"500\"\n",
    "    elif pred == \"-1\":\n",
    "        prediction = \"-1\"\n",
    "    else:\n",
    "        prediction=\"999\"\n",
    "\n",
    "    return flask.render_template('index.html', prediction=prediction)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#@app.route('/train', methods=['POST'])\n",
    "\n",
    "#def train():\n",
    "#    from train import Score\n",
    "#    from subprocess import call\n",
    "#    call([\"python\", \"train.py\"])\n",
    "   \n",
    "#    Accuracy=Score.Score()\n",
    "#    return flask.render_template('index.html', Accuracy=round(Accuracy,2))\n",
    "\n",
    "@app.route('/graph', methods=['POST'])\n",
    "\n",
    "def graph():\n",
    "    return flask.render_template('graph.html')\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # clf = joblib.load('quora_model.pkl')\n",
    "    # count_vect = joblib.load('quora_vectorizer.pkl')\n",
    "    app.run(host='localhost', port=8080)\n",
    "    #app.run(debug=False)\n",
    "    # from train import MultiColumnLabelEncoder\n",
    "   # from train import Score\n",
    "\n",
    "    # app.run(host='localhost', port=8081)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze >> req1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58430537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "explainer = ClassifierExplainer(classifier, X_test, y_test)\n",
    "\n",
    "ExplainerDashboard(explainer).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815760e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdc794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://18.213.113.195:27017/admin?gssapiServiceName=mongodb\")\n",
    "mydatabase = client.admin\n",
    "mydatabase\n",
    "mycollection=mydatabase[\"Loganalyser\"]\n",
    "mycollection\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://admin:password@18.213.113.195:27017/admin?gssapiServiceName=mongodb\")\n",
    "\n",
    "\n",
    "for db in client.list_databases():\n",
    "    print(db)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import certifi\n",
    "ca = certifi.where()\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://dbadmin:Pa11word-1@mongodbcluster.ctuax.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\",tlsCAFile=ca)\n",
    "\n",
    "mydatabase = client.apicreport\n",
    "collection_name = mydatabase.apiclogs\n",
    "cursor = collection_name.find()\n",
    "list_cur = list(cursor)\n",
    "df_p = DataFrame(list_cur)\n",
    "df_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import certifi\n",
    "ca = certifi.where()\n",
    "\n",
    "#client = pymongo.MongoClient(\"mongodb://admin:Pa11word-1@44.201.53.209/admin\") # defaults to port 27017\n",
    "client = pymongo.MongoClient(\"mongodb+srv://dbadmin:Pa11word-1@mongodbcluster.ctuax.mongodb.net/myFirstDatabase?retryWrites=true&w=majority\",tlsCAFile=ca)\n",
    "\n",
    "db = client.apicreport\n",
    "print(\"db = \", db)\n",
    "\n",
    "\n",
    "# print the number of documents in a collection\n",
    "#print(\"count\", db.temproles.count())\n",
    "\n",
    "#for db in client.list_databases():\n",
    "#    print(\"db_name=\" ,db)\n",
    "    \n",
    "collection_name = db.apiclogs\n",
    "print(\"collection_name=\",collection_name)\n",
    "\n",
    "\n",
    "cursor = collection_name.find()\n",
    "print(\"cursor=\", cursor)\n",
    "\n",
    "for db1 in client.list_databases():\n",
    "    print(\"db1\", db1)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(list(cursor))\n",
    "print(\"Data = \", data)\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9646480",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
